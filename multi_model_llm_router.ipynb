{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Установка и импорт библиотек**"
      ],
      "metadata": {
        "id": "HancbKvn0bEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка OpenAI SDK\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "aYXDH9StCRak"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import time\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "a9-MafOI0flR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Загрузка API-ключа и инициализация клиента**"
      ],
      "metadata": {
        "id": "nQVzGxmCI2Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем API-ключ из Google Colab Secrets\n",
        "API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Инициализация клиента OpenAI\n",
        "client = OpenAI(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "Kjr18NgHB9gW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Конфигурация моделей и параметров**\n",
        "### **Назначение:** централизованная настройка моделей, промптов и оценки стоимости"
      ],
      "metadata": {
        "id": "DG3wP0Z60Rud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Конфигурация моделей\n",
        "# NOTE: price_* — это ОЦЕНОЧНАЯ стоимость, используется для сравнения, не реальный биллинг\n",
        "\n",
        "CONFIG = {\n",
        "    \"intent\": {\n",
        "        \"model\": \"gpt-4o-mini\",\n",
        "        \"system_prompt\": (\n",
        "            \"You are a helpful assistant. \"\n",
        "            \"Classify the following user query as either 'simple' or 'hard'. \"\n",
        "            \"Return ONLY one word: simple or hard.\"\n",
        "        ),\n",
        "        \"max_tokens\": 5,\n",
        "        \"price_input\": 0.15,\n",
        "        \"price_output\": 0.60,\n",
        "    },\n",
        "    \"easy\": {\n",
        "        \"model\": \"gpt-4o-mini\",\n",
        "        \"system_prompt\": \"You are a helpful assistant.\",\n",
        "        \"max_tokens\": None,\n",
        "        \"price_input\": 0.15,\n",
        "        \"price_output\": 0.60,\n",
        "    },\n",
        "    \"hard\": {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"system_prompt\": \"You are a helpful assistant.\",\n",
        "        \"max_tokens\": None,\n",
        "        \"price_input\": 5.00,\n",
        "        \"price_output\": 15.00,\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "zerP80D7IvpL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Функция отправки запроса в модель**\n",
        "### **Назначение:** единая точка общения с LLM, замер latency и оценки стоимости"
      ],
      "metadata": {
        "id": "YIWuDcOLsv9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(prompt: str, model_type: str):\n",
        "    \"\"\"\n",
        "    Отправляет запрос в указанную модель,\n",
        "    возвращает оценку стоимости, latency и intent (если применимо).\n",
        "    \"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=CONFIG[model_type][\"model\"],\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": CONFIG[model_type][\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        max_tokens=CONFIG[model_type][\"max_tokens\"],\n",
        "    )\n",
        "\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    # Извлекаем текст ответа\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Intent нужен только для классификатора\n",
        "    intent = None\n",
        "    if model_type == \"intent\":\n",
        "        content_lower = content.lower()\n",
        "        intent = \"hard\" if \"hard\" in content_lower else \"simple\"\n",
        "\n",
        "    # Подсчёт примерной стоимости\n",
        "    tokens_input = response.usage.prompt_tokens\n",
        "    tokens_output = response.usage.completion_tokens\n",
        "\n",
        "    estimated_price = (\n",
        "        tokens_input * CONFIG[model_type][\"price_input\"]\n",
        "        + tokens_output * CONFIG[model_type][\"price_output\"]\n",
        "    )\n",
        "\n",
        "    print(f\"[MODEL: {model_type}] → {content}\")\n",
        "\n",
        "    return estimated_price, latency, intent"
      ],
      "metadata": {
        "id": "D1iYJCVfIwDO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Тестовые запросы**\n",
        "### **Назначение:** подготовка запросов разной сложности"
      ],
      "metadata": {
        "id": "r0uU7uevwY7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EASY_QUERY = \"Give me a recipe for a classic margarita cocktail.\"\n",
        "\n",
        "HARD_QUERY = (\n",
        "    \"How do memory-mapped files (mmap) provide advantages over traditional \"\n",
        "    \"read/write system calls for certain types of I/O operations?\"\n",
        ")"
      ],
      "metadata": {
        "id": "sYKCKH3ptXrQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Тестируем классификатор намерений (Intent Classifier)**\n",
        "### **Назначение:** проверяем, как модель различает сложность задач"
      ],
      "metadata": {
        "id": "ORlQlZAHJkju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing intent classification:\\n\")\n",
        "\n",
        "call_model(EASY_QUERY, \"intent\")\n",
        "call_model(HARD_QUERY, \"intent\")"
      ],
      "metadata": {
        "id": "NqBhw78wwLtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd836d41-0f11-473a-add2-c89e5383a3cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing intent classification:\n",
            "\n",
            "[MODEL: intent] → simple\n",
            "[MODEL: intent] → hard\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.649999999999999, 1.6125001907348633, 'hard')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Используем только мощную модель (baseline)**\n",
        "### **Назначение:** измеряем latency и стоимость без оптимизации"
      ],
      "metadata": {
        "id": "m6FAO_GaJtyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUsing ONLY powerful model (gpt-4o):\\n\")\n",
        "\n",
        "price_1, latency_1, _ = call_model(EASY_QUERY, \"hard\")\n",
        "price_2, latency_2, _ = call_model(HARD_QUERY, \"hard\")\n",
        "\n",
        "total_price = price_1 + price_2\n",
        "total_latency = latency_1 + latency_2\n",
        "\n",
        "print(\"\\n-------------------------------\")\n",
        "print(f\"TOTAL PRICE (estimate): {total_price:.2f}\")\n",
        "print(f\"TOTAL LATENCY: {total_latency:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHHwMYbiJw5X",
        "outputId": "54ddb973-6f7e-48ea-8379-c2f1d76f51eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using ONLY powerful model (gpt-4o):\n",
            "\n",
            "[MODEL: hard] → A classic margarita is a refreshing and simple cocktail that's perfect for any occasion. Here’s how you can make one:\n",
            "\n",
            "### Ingredients:\n",
            "- 2 oz (60 ml) tequila (preferably blanco)\n",
            "- 1 oz (30 ml) Cointreau or triple sec\n",
            "- 1 oz (30 ml) freshly squeezed lime juice\n",
            "- Salt for rimming the glass (optional)\n",
            "- Lime wedge for garnish\n",
            "- Ice\n",
            "\n",
            "### Instructions:\n",
            "\n",
            "1. **Prepare the Glass:**\n",
            "   - If you like a salted rim, run a lime wedge around the outer edge of your glass to moisten it.\n",
            "   - Dip the rim into a small plate of salt, ensuring it's evenly coated. Shake off any excess.\n",
            "\n",
            "2. **Mix the Cocktail:**\n",
            "   - Fill a cocktail shaker with ice.\n",
            "   - Pour the tequila, Cointreau (or triple sec), and freshly squeezed lime juice into the shaker.\n",
            "   - Shake well until the outside of the shaker feels cold—about 15 to 20 seconds.\n",
            "\n",
            "3. **Serve:**\n",
            "   - Fill your prepared glass with ice (if not serving straight up).\n",
            "   - Strain the mixture from the shaker into the glass.\n",
            "\n",
            "4. **Garnish:**\n",
            "   - Garnish with a lime wedge on the rim of the glass.\n",
            "\n",
            "5. **Enjoy!**\n",
            "\n",
            "Feel free to adjust the sweetness or acidity to your preference by adding more or less Cointreau/triple sec or lime juice. Cheers!\n",
            "[MODEL: hard] → Memory-mapped files (mmap) offer several advantages over traditional read and write system calls for certain types of I/O operations. Here are some of the key benefits:\n",
            "\n",
            "1. **Performance and Efficiency**: \n",
            "   - **Reduced Copying**: Memory-mapping a file allows the file contents to be mapped directly into the process's address space, which reduces the need for data to be copied between kernel space and user space. Traditional read and write operations typically involve copying data from disk to kernel buffers, and then from kernel buffers to user space.\n",
            "   - **Page-based I/O**: mmap leverages the virtual memory system to load pages from the file as needed (on a page fault), which can result in more efficient data loading patterns, especially for large files. The operating system only loads pages into memory that are actually accessed.\n",
            "\n",
            "2. **Simplified Access**: \n",
            "   - **Random Access**: With mmap, you can access file contents as if they were part of the process's memory using simple pointer arithmetic, rather than dealing with explicit read and write calls and managing buffers manually.\n",
            "   - **Convenient for Certain Applications**: This is advantageous for applications that require frequent and non-sequential access to large files, such as databases or video processing applications.\n",
            "\n",
            "3. **Automatic Synchronization**:\n",
            "   - **Write-Back Mechanism**: Changes made to the mapped memory region can be automatically synchronized back to the file on disk, depending on the mapping settings (e.g., using `MAP_SHARED`). This can simplify managing consistency between the in-memory data and the file on disk.\n",
            "\n",
            "4. **Memory Sharing**:\n",
            "   - **Shared Mappings**: Multiple processes can map the same file into their address spaces, and if shared mapping is used (`MAP_SHARED`), changes made by one process are visible to others. This is useful for inter-process communication and shared data scenarios.\n",
            "\n",
            "5. **Reduced System Call Overhead**:\n",
            "   - By eliminating the need for frequent read and write system calls, mmap can significantly reduce system call overhead in scenarios where large amounts of data need to be transferred between disk and memory.\n",
            "\n",
            "6. **Lazy Loading**:\n",
            "   - Because mmap leverages demand paging, not all pages are loaded into memory immediately. Instead, pages are loaded as they are accessed, which can be beneficial for large files where not all parts of the file need to be in memory at the same time.\n",
            "\n",
            "However, it's also worth noting that mmap comes with certain caveats and is not always the ideal solution:\n",
            "\n",
            "- **Limited Portability**: While mmap is widely supported on UNIX-like systems, its behavior can vary across different operating systems.\n",
            "- **Complex Error Handling**: Handling page faults dynamically can introduce complexities in error handling, especially if the backing file is resized or becomes unavailable.\n",
            "- **Resource Limits**: mmap can lead to increased memory consumption if not used carefully, as it relies on the virtual memory subsystem.\n",
            "\n",
            "Overall, the choice between using mmap and traditional read/write calls depends on the specific requirements of the application, including the nature of the file access patterns and the need for performance optimization.\n",
            "\n",
            "-------------------------------\n",
            "TOTAL PRICE (estimate): 14245.00\n",
            "TOTAL LATENCY: 17.41 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Реализация мульти-модельного роутера**\n",
        "### **Назначение:** автоматический выбор модели на основе intent"
      ],
      "metadata": {
        "id": "oKRpFHNxJ7jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def router(query: str):\n",
        "    \"\"\"\n",
        "    Определяет сложность запроса и маршрутизирует его\n",
        "    в подходящую модель (easy / hard).\n",
        "    \"\"\"\n",
        "\n",
        "    # Шаг 1: классификация intent\n",
        "    price_intent, latency_intent, intent = call_model(query, \"intent\")\n",
        "\n",
        "    # Шаг 2: маршрутизация\n",
        "    if intent == \"hard\":\n",
        "        print(\"[ROUTER] Using HARD model\\n\")\n",
        "        price_answer, latency_answer, _ = call_model(query, \"hard\")\n",
        "    else:\n",
        "        print(\"[ROUTER] Using EASY model\\n\")\n",
        "        price_answer, latency_answer, _ = call_model(query, \"easy\")\n",
        "\n",
        "    total_price = price_intent + price_answer\n",
        "    total_latency = latency_intent + latency_answer\n",
        "\n",
        "    return total_price, total_latency"
      ],
      "metadata": {
        "id": "_G80wEOXJ9WI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Используем мульти-модельность**\n",
        "### **Назначение:** сравнение эффективности маршрутизации"
      ],
      "metadata": {
        "id": "d6aQ7dVjKCf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUsing MULTI-MODEL ROUTER:\\n\")\n",
        "\n",
        "price_1, latency_1 = router(EASY_QUERY)\n",
        "price_2, latency_2 = router(HARD_QUERY)\n",
        "\n",
        "total_price = price_1 + price_2\n",
        "total_latency = latency_1 + latency_2\n",
        "\n",
        "print(\"\\n-------------------------------\")\n",
        "print(f\"TOTAL PRICE (estimate): {total_price:.2f}\")\n",
        "print(f\"TOTAL LATENCY: {total_latency:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvgKa1pdKFNx",
        "outputId": "8c371ba8-1224-4c07-dcb4-deb937f43eb5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using MULTI-MODEL ROUTER:\n",
            "\n",
            "[MODEL: intent] → simple\n",
            "[ROUTER] Using EASY model\n",
            "\n",
            "[MODEL: easy] → Certainly! Here’s a classic margarita recipe that you can easily make at home.\n",
            "\n",
            "### Classic Margarita Recipe\n",
            "\n",
            "#### Ingredients:\n",
            "- 2 oz (60 ml) tequila (preferably 100% agave)\n",
            "- 1 oz (30 ml) fresh lime juice\n",
            "- 1 oz (30 ml) Cointreau or triple sec\n",
            "- Salt (for rimming the glass)\n",
            "- Lime wedge (for garnish)\n",
            "- Ice\n",
            "\n",
            "#### Instructions:\n",
            "\n",
            "1. **Prepare the Glass**: \n",
            "   - Rub the lime wedge around the rim of your glass to moisten it. \n",
            "   - Dip the rim into a plate of salt to coat it evenly. Set the glass aside.\n",
            "\n",
            "2. **Mix the Ingredients**: \n",
            "   - In a shaker, combine the tequila, fresh lime juice, and Cointreau (or triple sec).\n",
            "   - Fill the shaker with ice and shake vigorously for about 15-20 seconds until well chilled.\n",
            "\n",
            "3. **Strain**: \n",
            "   - Fill your prepared glass with ice (if desired) and strain the margarita mixture into the glass.\n",
            "\n",
            "4. **Garnish**: \n",
            "   - Garnish with a lime wedge on the rim of the glass.\n",
            "\n",
            "5. **Serve**: \n",
            "   - Enjoy your refreshing classic margarita!\n",
            "\n",
            "### Tips:\n",
            "- For a blended margarita, blend all the ingredients with ice until smooth.\n",
            "- Adjust the sweetness by adding a little agave syrup if desired.\n",
            "- Use freshly squeezed lime juice for the best flavor.\n",
            "\n",
            "Cheers! Enjoy your margarita!\n",
            "[MODEL: intent] → hard\n",
            "[ROUTER] Using HARD model\n",
            "\n",
            "[MODEL: hard] → Memory-mapped files (mmap) can offer several advantages over traditional read/write system calls for certain types of I/O operations. Here are some of the key benefits:\n",
            "\n",
            "1. **Performance Improvement**: \n",
            "   - **Reduced System Calls**: Using mmap can reduce the number of system calls needed because the file content is mapped into the process's address space. Accessing data through the mapped region can be as fast as accessing memory.\n",
            "   - **Efficient Use of Page Cache**: Mmap uses the operating system's page cache directly, allowing data to be cached more efficiently. This avoids unnecessary data copying between kernel and user space.\n",
            "\n",
            "2. **Simplified Programming Model**:\n",
            "   - **Direct Memory Access**: With mmap, you can directly access data through pointers as if it's part of the process's memory. This can simplify code that requires frequent or complex access to data structures.\n",
            "   - **No Explicit I/O Operations**: There's no need for explicit read or write operations. Accessing data directly modifies memory, and the operating system takes care of syncing changes back to the file.\n",
            "\n",
            "3. **Automatic Synchronization**:\n",
            "   - **Demand Paging**: Mmap uses demand paging, loading pages into memory only when they're accessed, which can help with large files where only a portion might be needed at a time.\n",
            "   - **Lazy Updates**: Modifications to the file through mapped memory can be lazy-updated, where changes are written back to disk at a later time, or even explicitly controlled through msync.\n",
            "\n",
            "4. **Large File Support**:\n",
            "   - Mmap can be especially useful for handling very large files since it abstracts away much of the complexity in accessing data compared to manual read and write buffering strategies.\n",
            "\n",
            "5. **Shared Memory**:\n",
            "   - **Inter-process Communication (IPC)**: By mapping a file into memory and sharing the mapping between processes, mmap provides a mechanism for IPC. Changes by one process can be seen by others mapping the same file.\n",
            "\n",
            "However, it's important to note that mmap also has some downsides. For instance, it can lead to page faults if not used carefully, and memory resources can become fragmented. Additionally, error handling can sometimes be more complex with memory-mapped files compared to traditional file I/O operations. Nonetheless, for certain use cases where the advantages align with the application's needs, mmap can be a powerful tool.\n",
            "\n",
            "-------------------------------\n",
            "TOTAL PRICE (estimate): 7626.05\n",
            "TOTAL LATENCY: 23.26 sec\n"
          ]
        }
      ]
    }
  ]
}